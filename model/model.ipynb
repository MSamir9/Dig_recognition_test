{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wgF8pDzlVRW"
      },
      "source": [
        "from tensorflow import keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.layers import Input\r\n",
        "from keras.models import Model\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.utils import to_categorical\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import MaxPool2D, Dense, Dropout, Conv2D ,Flatten \r\n",
        "from keras.utils import np_utils\r\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsgSZPwmlbdj",
        "outputId": "934d53c6-a135-443b-c8eb-19d6d47e8fae"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "def resize(img_array):\r\n",
        "    arr = np.empty((img_array.shape[0], 28, 28))\r\n",
        "\r\n",
        "    for i in range(len(img_array)):\r\n",
        "        img = img_array[i].reshape(28, 28).astype('uint8')\r\n",
        "        img = cv2.resize(img, (28, 28))\r\n",
        "        img = img.astype('float32')/255\r\n",
        "        arr[i] = img\r\n",
        "        \r\n",
        "    return arr\r\n",
        "\r\n",
        "\r\n",
        "x_train = resize(x_train)\r\n",
        "x_test = resize(x_test)\r\n",
        "x_train = np.stack((x_train,), axis=-1)\r\n",
        "x_test = np.stack((x_test,), axis=-1)\r\n",
        "y_train = to_categorical(y_train) \r\n",
        "\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=2020)\r\n",
        "x_train.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRS-9wBilh47"
      },
      "source": [
        "\r\n",
        "model=Sequential()\r\n",
        "model.add(Conv2D(128,(3,3),activation='relu',input_shape=(28,28,1)))\r\n",
        "model.add(MaxPool2D(2,2))\r\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))\r\n",
        "model.add(MaxPool2D(2,2))\r\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(256,activation='relu'))\r\n",
        "model.add(Dense(128,activation='relu'))\r\n",
        "model.add(Dense(64,activation='relu'))\r\n",
        "model.add(Dense(10,activation='softmax'))\r\n",
        "\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljs5Lej9oQyI",
        "outputId": "68f95d24-3af1-4745-a8bf-d6aa9d5df873"
      },
      "source": [
        "INIT_LR = 1e-3\r\n",
        "EPOCHS = 10\r\n",
        "BS = 32\r\n",
        "print(\"[INFO] compiling model...\")\r\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\r\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9eBG2Y2oqBs",
        "outputId": "79c8c611-e6d4-4b52-deaa-5b55454052f5"
      },
      "source": [
        "# train the head of the network\r\n",
        "\r\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), \r\n",
        "          epochs=10, batch_size=BS)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 121s 80ms/step - loss: 0.1934 - accuracy: 0.9407 - val_loss: 0.0617 - val_accuracy: 0.9794\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 119s 79ms/step - loss: 0.0688 - accuracy: 0.9796 - val_loss: 0.0465 - val_accuracy: 0.9857\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 120s 80ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.0466 - val_accuracy: 0.9872\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 120s 80ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 0.0343 - val_accuracy: 0.9901\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 119s 80ms/step - loss: 0.0324 - accuracy: 0.9900 - val_loss: 0.0338 - val_accuracy: 0.9905\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 121s 81ms/step - loss: 0.0256 - accuracy: 0.9918 - val_loss: 0.0371 - val_accuracy: 0.9905\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 121s 80ms/step - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.0357 - val_accuracy: 0.9907\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 120s 80ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0305 - val_accuracy: 0.9914\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 122s 81ms/step - loss: 0.0152 - accuracy: 0.9952 - val_loss: 0.0275 - val_accuracy: 0.9933\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 120s 80ms/step - loss: 0.0131 - accuracy: 0.9958 - val_loss: 0.0351 - val_accuracy: 0.9909\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdfb27a9d68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbMvM8WWwdyk",
        "outputId": "468c8781-6071-4d8b-8802-b841d468d324"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "\r\n",
        "class_to_label_map = {'zero' : 0, 'one' : 1, 'two' : 2, 'three': 3, \"four\": 4, \"five\": 5, \"six\": 6, \"seven\" : 7, \"eight\": 8, \"nine\": 9}\r\n",
        "\r\n",
        "print(\"[INFO] evaluating network...\")\r\n",
        "predIdxs = model.predict(x_test, batch_size=BS)\r\n",
        "\r\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\r\n",
        "print(classification_report(y_test.argmax(axis=1), predIdxs, target_names= class_to_label_map))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        zero       0.99      0.99      0.99      1148\n",
            "         one       1.00      0.99      0.99      1380\n",
            "         two       0.99      0.99      0.99      1184\n",
            "       three       1.00      0.99      0.99      1252\n",
            "        four       0.98      1.00      0.99      1191\n",
            "        five       0.99      0.99      0.99      1093\n",
            "         six       0.99      0.99      0.99      1148\n",
            "       seven       0.99      0.99      0.99      1219\n",
            "       eight       0.99      0.99      0.99      1166\n",
            "        nine       0.99      0.98      0.98      1219\n",
            "\n",
            "    accuracy                           0.99     12000\n",
            "   macro avg       0.99      0.99      0.99     12000\n",
            "weighted avg       0.99      0.99      0.99     12000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uTBOYVjwm9Y",
        "outputId": "11894e20-79a3-49c6-985b-bba4828f63fc"
      },
      "source": [
        "# show the confusion matrix and accuracy\r\n",
        "\r\n",
        "cm = confusion_matrix(y_test.argmax(axis=1), predIdxs)\r\n",
        "\r\n",
        "total = sum(sum(cm))\r\n",
        "s=0\r\n",
        "for i in range(0,10):\r\n",
        "  s=s+cm[i,i]\r\n",
        "\r\n",
        "acc =  s/ total\r\n",
        "\r\n",
        "print(cm)\r\n",
        "print(\"acc: {:.4f}\".format(acc))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1142    0    0    0    2    1    1    0    0    2]\n",
            " [   1 1371    1    0    1    0    0    5    1    0]\n",
            " [   2    0 1174    1    3    0    0    1    2    1]\n",
            " [   1    0    2 1235    0    5    1    2    2    4]\n",
            " [   0    1    0    0 1186    0    2    0    0    2]\n",
            " [   0    3    0    1    0 1082    2    1    3    1]\n",
            " [   4    0    1    0    1    0 1140    0    2    0]\n",
            " [   0    0    3    0    0    0    0 1210    1    5]\n",
            " [   1    1    2    1    0    0    2    0 1158    1]\n",
            " [   2    0    0    0   14    5    1    1    3 1193]]\n",
            "acc: 0.9909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilf2YMbSwza1",
        "outputId": "1c1d9f3e-dbc5-44f0-8e2a-7a3edac598a0"
      },
      "source": [
        "# Save whole model for download\r\n",
        "model.save(\"model.h5\")\r\n",
        "!pip install tensorflowjs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/c8/c52e21c49b3baf0845e395241046a993e244dd4b94c9827a8cd2d9b18927/tensorflowjs-2.7.0-py3-none-any.whl (62kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 15.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 20kB 21.0MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 30kB 20.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 40kB 18.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 51kB 17.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 61kB 18.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.3.0)\n",
            "Collecting tensorflow-hub<0.10,>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/83/a7df82744a794107641dad1decaad017d82e25f0e1f761ac9204829eef96/tensorflow_hub-0.9.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 14.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py<3,>=2.8.0->tensorflowjs) (1.18.5)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.35.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.33.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<3,>=2.1.0->tensorflowjs) (50.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (2.0.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (4.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Installing collected packages: tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: tensorflow-hub 0.10.0\n",
            "    Uninstalling tensorflow-hub-0.10.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.10.0\n",
            "Successfully installed tensorflow-hub-0.9.0 tensorflowjs-2.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Eyr5L74w5_N",
        "outputId": "6bdd93cf-3224-4f5a-fada-4df65407726d"
      },
      "source": [
        "!tensorflowjs_converter --input_format keras '/content/model.h5' '/content/model'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-09 13:49:38.621173: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
